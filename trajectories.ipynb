{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import json\n",
    "from trajectory import *\n",
    "\n",
    "getDictKeys = lambda dict_: list(dict_.keys())\n",
    "getDictValues = lambda dict_: list(dict_.values())\n",
    "getDictItems = lambda dict_: list(dict_.items())\n",
    "euclDist = lambda l1, l2: sum([(l1[i] - l2[i])**2 for i in range(len(l1))])**0.5\n",
    "\n",
    "t = Trajectory(r\"trajectories.txt\")\n",
    "m = t.constructWeightMatrix(None, True)\n",
    "\n",
    "edges_dict = dict()\n",
    "for p1 in t.unique_points:\n",
    "    for p2 in t.unique_points:\n",
    "        if (p1 != p2) and (m.loc[p1, p2] > 0):\n",
    "            edges_dict[(p1, p2)] = m.loc[p1, p2]\n",
    "edges_weights = getDictItems(edges_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('A', 'B'), 1.0),\n",
       " (('A', 'D'), 1.0),\n",
       " (('A', 'E'), 5.0),\n",
       " (('A', 'G'), 415.0),\n",
       " (('A', 'I'), 1.0),\n",
       " (('A', 'J'), 1.0),\n",
       " (('B', 'A'), 1584.0),\n",
       " (('B', 'D'), 4.0),\n",
       " (('B', 'F'), 1771.0),\n",
       " (('B', 'G'), 1869.0),\n",
       " (('B', 'H'), 548.0),\n",
       " (('B', 'I'), 1.0),\n",
       " (('B', 'J'), 603.0),\n",
       " (('C', 'A'), 1622.0),\n",
       " (('C', 'B'), 2112.0),\n",
       " (('C', 'E'), 1.0),\n",
       " (('C', 'F'), 1366.0),\n",
       " (('C', 'G'), 1647.0),\n",
       " (('C', 'H'), 1921.0),\n",
       " (('C', 'I'), 1968.0),\n",
       " (('C', 'J'), 1913.0),\n",
       " (('D', 'A'), 1676.0),\n",
       " (('D', 'B'), 2259.0),\n",
       " (('D', 'C'), 345.0),\n",
       " (('D', 'E'), 1406.0),\n",
       " (('D', 'F'), 1358.0),\n",
       " (('D', 'G'), 1618.0),\n",
       " (('D', 'H'), 1979.0),\n",
       " (('D', 'I'), 2131.0),\n",
       " (('D', 'J'), 2054.0),\n",
       " (('E', 'A'), 1990.0),\n",
       " (('E', 'B'), 1397.0),\n",
       " (('E', 'C'), 1509.0),\n",
       " (('E', 'F'), 1999.0),\n",
       " (('E', 'G'), 2338.0),\n",
       " (('E', 'H'), 1536.0),\n",
       " (('E', 'I'), 1110.0),\n",
       " (('E', 'J'), 1545.0),\n",
       " (('F', 'A'), 725.0),\n",
       " (('F', 'B'), 1.0),\n",
       " (('F', 'C'), 1.0),\n",
       " (('F', 'E'), 5.0),\n",
       " (('F', 'G'), 287.0),\n",
       " (('F', 'H'), 3.0),\n",
       " (('F', 'I'), 3.0),\n",
       " (('F', 'J'), 2.0),\n",
       " (('G', 'B'), 3.0),\n",
       " (('G', 'C'), 1.0),\n",
       " (('G', 'E'), 1.0),\n",
       " (('G', 'F'), 1.0),\n",
       " (('G', 'H'), 1.0),\n",
       " (('G', 'I'), 2.0),\n",
       " (('G', 'J'), 2.0),\n",
       " (('H', 'A'), 1201.0),\n",
       " (('H', 'B'), 1.0),\n",
       " (('H', 'C'), 2.0),\n",
       " (('H', 'D'), 3.0),\n",
       " (('H', 'F'), 1672.0),\n",
       " (('H', 'G'), 1789.0),\n",
       " (('H', 'J'), 31.0),\n",
       " (('I', 'A'), 1557.0),\n",
       " (('I', 'B'), 172.0),\n",
       " (('I', 'D'), 1.0),\n",
       " (('I', 'E'), 1.0),\n",
       " (('I', 'F'), 1800.0),\n",
       " (('I', 'G'), 2052.0),\n",
       " (('I', 'H'), 630.0),\n",
       " (('I', 'J'), 709.0),\n",
       " (('J', 'A'), 1177.0),\n",
       " (('J', 'D'), 4.0),\n",
       " (('J', 'E'), 1.0),\n",
       " (('J', 'F'), 1573.0),\n",
       " (('J', 'G'), 1694.0),\n",
       " (('J', 'I'), 2.0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Array in Ascending Order:\n",
      "[(('A', 'B'), 1.0), (('A', 'D'), 1.0), (('A', 'I'), 1.0), (('A', 'J'), 1.0), (('B', 'I'), 1.0), (('C', 'E'), 1.0), (('F', 'B'), 1.0), (('F', 'C'), 1.0), (('G', 'C'), 1.0), (('G', 'E'), 1.0), (('G', 'F'), 1.0), (('G', 'H'), 1.0), (('H', 'B'), 1.0), (('I', 'D'), 1.0), (('I', 'E'), 1.0), (('J', 'E'), 1.0), (('H', 'C'), 2.0), (('G', 'I'), 2.0), (('G', 'J'), 2.0), (('F', 'J'), 2.0), (('J', 'I'), 2.0), (('F', 'H'), 3.0), (('F', 'I'), 3.0), (('G', 'B'), 3.0), (('H', 'D'), 3.0), (('B', 'D'), 4.0), (('J', 'D'), 4.0), (('F', 'E'), 5.0), (('A', 'E'), 5.0), (('H', 'J'), 31.0), (('I', 'B'), 172.0), (('F', 'G'), 287.0), (('D', 'C'), 345.0), (('A', 'G'), 415.0), (('B', 'H'), 548.0), (('B', 'J'), 603.0), (('I', 'H'), 630.0), (('I', 'J'), 709.0), (('F', 'A'), 725.0), (('E', 'I'), 1110.0), (('J', 'A'), 1177.0), (('H', 'A'), 1201.0), (('D', 'F'), 1358.0), (('C', 'F'), 1366.0), (('E', 'B'), 1397.0), (('D', 'E'), 1406.0), (('E', 'C'), 1509.0), (('E', 'H'), 1536.0), (('E', 'J'), 1545.0), (('I', 'A'), 1557.0), (('J', 'F'), 1573.0), (('B', 'A'), 1584.0), (('D', 'G'), 1618.0), (('C', 'A'), 1622.0), (('C', 'G'), 1647.0), (('H', 'F'), 1672.0), (('D', 'A'), 1676.0), (('J', 'G'), 1694.0), (('B', 'F'), 1771.0), (('H', 'G'), 1789.0), (('I', 'F'), 1800.0), (('B', 'G'), 1869.0), (('C', 'J'), 1913.0), (('C', 'H'), 1921.0), (('C', 'I'), 1968.0), (('D', 'H'), 1979.0), (('E', 'A'), 1990.0), (('E', 'F'), 1999.0), (('I', 'G'), 2052.0), (('D', 'J'), 2054.0), (('C', 'B'), 2112.0), (('D', 'I'), 2131.0), (('D', 'B'), 2259.0), (('E', 'G'), 2338.0)]\n"
     ]
    }
   ],
   "source": [
    "size = len(edges_weights)\n",
    "\n",
    "quickSort(edges_weights, 0, size - 1)\n",
    "\n",
    "print('Sorted Array in Ascending Order:')\n",
    "print(edges_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from functools import reduce\n",
    "# from copy import deepcopy\n",
    "# import json\n",
    "\n",
    "# import json\n",
    "\n",
    "# def write_to_json(data, filename):\n",
    "#     \"\"\"\n",
    "#     Write a dictionary to a JSON file.\n",
    "    \n",
    "#     Args:\n",
    "#         data: Dictionary to be written to the file.\n",
    "#         filename: Name of the JSON file.\n",
    "#     \"\"\"\n",
    "#     with open(filename, 'w') as json_file:\n",
    "#         json.dump(data, json_file, indent=4)\n",
    "\n",
    "# def read_from_json(filename):\n",
    "#     \"\"\"\n",
    "#     Read a JSON file and return its content as a dictionary.\n",
    "    \n",
    "#     Args:\n",
    "#         filename: Name of the JSON file.\n",
    "        \n",
    "#     Returns:\n",
    "#         Dictionary containing the content of the JSON file.\n",
    "#     \"\"\"\n",
    "#     with open(filename, 'r') as json_file:\n",
    "#         data = json.load(json_file)\n",
    "#     return data\n",
    "\n",
    "\n",
    "\n",
    "# trajectory_weights = pd.read_excel(r\"trajectory_weights.xlsx\", index_col=0)\n",
    "# next_steps = trajectory_weights.columns.values\n",
    "# getIdxNextStep = lambda next_step: np.where(next_steps == next_step)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getDictKeys = lambda dict_: list(dict_.keys())\n",
    "# getDictValues = lambda dict_: list(dict_.values())\n",
    "# getDictItems = lambda dict_: list(dict_.items())\n",
    "# euclDist = lambda l1, l2: sum([(l1[i] - l2[i])**2 for i in range(len(l1))])**0.5\n",
    "\n",
    "# class PointError(Exception):\n",
    "#     def __init__(self, message):\n",
    "#         self.message = message\n",
    "#         super().__init__(self.message)\n",
    "\n",
    "\n",
    "# class Trajectory:\n",
    "#     \"\"\"Class to read text file containing trajectories and perform some filter operations on those trajectories.\"\"\"\n",
    "#     def __init__(self, file_path):\n",
    "#         self.file_path = file_path\n",
    "#         self.trajectories_str = [] # Assign list for trajectories as strings (in text file)\n",
    "#         self.trajectories = [] # Assign list for trajectories as lists\n",
    "#         self.read() # Read trajectory text file\n",
    "#         self.unique_points = self.getUniquePoints()\n",
    "#         self.unique_trajectories = self.getUniqueTrajectories()\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.trajectories)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         return self.trajectories[index]\n",
    "    \n",
    "#     def __contains__(self, item):\n",
    "#         return item in self.trajectories\n",
    "    \n",
    "#     def append(self, item):\n",
    "#         self.trajectories.append(item)\n",
    "    \n",
    "#     def extend(self, items):\n",
    "#         self.trajectories.extend(items)\n",
    "\n",
    "#     def getTrajectories(self):\n",
    "#         return self.trajectories\n",
    "    \n",
    "#     def getTrajectoriesStr(self):\n",
    "#         return self.trajectories_str\n",
    "    \n",
    "#     def getUniqueTrajectories(self):\n",
    "#         \"\"\"Returns the unique trajectories in the list of trajectories.\"\"\"\n",
    "#         unique_trajectories = []\n",
    "#         for trajectory in self.trajectories:\n",
    "#             if trajectory not in unique_trajectories:\n",
    "#                 unique_trajectories.append(trajectory)\n",
    "#         return unique_trajectories\n",
    "\n",
    "#     def read(self):\n",
    "#         \"\"\"Reads the trajectories from the text file and stores them.\"\"\"\n",
    "#         # Open the file in read mode\n",
    "#         with open(self.file_path, 'r') as file:\n",
    "#             # Read each line of the file using a loop\n",
    "#             for line in file:\n",
    "#                 # Process each line as needed\n",
    "#                 newline = line.strip()  # Remove newline character\n",
    "#                 self.trajectories_str.append(newline) # Add to string list\n",
    "#                 self.trajectories.append(newline.split()) # Add to nested list\n",
    "\n",
    "#     def describe(self):\n",
    "#         \"\"\"Returns some useful information about the trajectories.\"\"\"\n",
    "#         # Print nicely\n",
    "#         for info, nr in zip([\"Total\", \"Unique\", \"# points\"], [len(self.trajectories), len(self.unique_trajectories),\n",
    "#                                                               len(self.unique_points)]):\n",
    "#             print(f\"{info}\", end=\": \")\n",
    "#             print(f\"{nr}\")\n",
    "#             print(\"_\"*15)\n",
    "    \n",
    "#     def getUniquePoints(self):\n",
    "#         \"\"\"Returns unique points in the trajectories.\"\"\"\n",
    "#         # Flatten the nested list into a single list\n",
    "#         flat_list = [item for sublist in self.trajectories for item in sublist]\n",
    "#         # Get unique elements using set\n",
    "#         unique_elements = set(flat_list)\n",
    "#         # Convert the unique elements back to a list if needed\n",
    "#         unique_elements_list = sorted(list(unique_elements))\n",
    "#         return unique_elements_list\n",
    "    \n",
    "#     def filterOnStartPoint(self, startPoint):\n",
    "#         \"\"\"Filter the trajectories on a given start node and return trajectories having that node as a starting point.\"\"\"\n",
    "#         if startPoint not in self.unique_points:\n",
    "#             raise PointError(f\"Point {startPoint} not found!\")\n",
    "#         # Filter trajectories based on starting point\n",
    "#         filtered_trajectories = [trajectory for trajectory in self.trajectories if trajectory[0] == startPoint]\n",
    "#         return filtered_trajectories\n",
    "    \n",
    "#     def filterOnStartPoints(self, startPoints):\n",
    "#         \"\"\"Filter the trajectories on given start nodes and return trajectories having one of these nodes as a starting point.\"\"\"\n",
    "#         for point in startPoints:\n",
    "#             if point not in self.unique_points:\n",
    "#                 raise PointError(f\"Point {point} not found!\")\n",
    "#         # Filter trajectories based on starting point\n",
    "#         filtered_trajectories = []\n",
    "#         for point in startPoints:\n",
    "#             filtered_trajectories.extend(self.filterOnStartPoint(point))\n",
    "#         return filtered_trajectories\n",
    "    \n",
    "#     def filterOnEndPoint(self, endPoint):\n",
    "#         \"\"\"Filter the trajectories on a given end node and return trajectories having that node as an ending point.\"\"\"\n",
    "#         if endPoint not in self.unique_points:\n",
    "#             raise PointError(f\"Point {endPoint} not found!\")\n",
    "#         # Filter trajectories based on ending point\n",
    "#         filtered_trajectories = [trajectory for trajectory in self.trajectories if trajectory[-1] == endPoint]\n",
    "#         return filtered_trajectories\n",
    "    \n",
    "#     def filterOnEndPoints(self, endPoints):\n",
    "#         \"\"\"Filter the trajectories on given end nodes and return trajectories having one of these nodes as an ending point.\"\"\"\n",
    "#         for point in endPoints:\n",
    "#             if point not in self.unique_points:\n",
    "#                 raise PointError(f\"Point {point} not found!\")\n",
    "#         # Filter trajectories based on ending point\n",
    "#         filtered_trajectories = []\n",
    "#         for point in endPoints:\n",
    "#             filtered_trajectories.extend(self.filterOnEndPoint(point))\n",
    "#         return filtered_trajectories\n",
    "    \n",
    "#     def filterOnIntermediatePoint(self, point, includeStart=False, includeEnd=False):\n",
    "#         \"\"\"Filter the trajectories on a given intermediate point and return trajectories having that node as a traversing point.\"\"\"\n",
    "#         if point not in self.unique_points:\n",
    "#             raise PointError(f\"Point {point} not found!\")\n",
    "#         # Filter trajectories based on intermediate point\n",
    "#         filtered_trajectories = [trajectory for trajectory in self.trajectories if point in trajectory]\n",
    "#         # Remove point if it is starting point (if specified)\n",
    "#         if not(includeStart):\n",
    "#             filtered_trajectories = [trajectory for trajectory in filtered_trajectories if trajectory[0] != point]\n",
    "#         # Remove point if it is ending point (if specified)\n",
    "#         if not(includeEnd):\n",
    "#             filtered_trajectories = [trajectory for trajectory in filtered_trajectories if trajectory[-1] != point]\n",
    "#         return filtered_trajectories\n",
    "    \n",
    "#     def filterOnIntermediatePoints(self, points, includeStart=False, includeEnd=False):\n",
    "#         \"\"\"Filter the trajectories on given intermediate nodes and return trajectories having one of these nodes as a traversing point.\"\"\"\n",
    "#         for point in points:\n",
    "#             if point not in self.unique_points:\n",
    "#                 raise PointError(f\"Point {point} not found!\")\n",
    "#         # Filter trajectories based on intermediate point\n",
    "#         filtered_trajectories = []\n",
    "#         for point in points:\n",
    "#             filtered_trajectories.extend(self.filterOnIntermediatePoint(point, includeStart, includeEnd))\n",
    "#         return filtered_trajectories\n",
    "    \n",
    "#     def filterOnLength(self, length):\n",
    "#         \"\"\"Filter the trajectories on a given number of nodes and return trajectories having that length.\"\"\"\n",
    "#         if length < 2:\n",
    "#             raise ValueError(\"Trajectories must have at least length 2!\")\n",
    "#         # Filter trajectories based on length\n",
    "#         filtered_trajectories = [trajectory for trajectory in self.trajectories if len(trajectory) == length]\n",
    "#         return filtered_trajectories\n",
    "    \n",
    "#     def filterOnLengths(self, lengths):\n",
    "#         \"Filter the trajectories on given lengths and return trajectories having one of these lengths.\"\n",
    "#         for length in lengths:\n",
    "#             if length < 2:\n",
    "#                 raise ValueError(\"Trajectories must have at least length 2!\")\n",
    "#         # Filter trajectories based on lengths\n",
    "#         filtered_trajectories = []\n",
    "#         for length in lengths:\n",
    "#             filtered_trajectories.extend(self.filterOnLength(length))\n",
    "#         return filtered_trajectories\n",
    "    \n",
    "#     def countTrajectories(self, reverse=True, relative=False):\n",
    "#         \"\"\"Returns a dictionary containing the count of each single trajectory in the trajectories.\"\"\"\n",
    "#         # Initialize an empty dictionary to store counts\n",
    "#         element_counts = {}\n",
    "\n",
    "#         # Count occurrences of each element\n",
    "#         for element in self.trajectories_str:\n",
    "#             if element in element_counts:\n",
    "#                 element_counts[element] += 1\n",
    "#             else:\n",
    "#                 element_counts[element] = 1\n",
    "        \n",
    "#         # Transform into tuple pairs\n",
    "#         element_counts = getDictItems(element_counts)\n",
    "#         element_counts = sorted(element_counts, key=lambda x: x[1], reverse=reverse)\n",
    "\n",
    "#         # Transform again into dictionary\n",
    "#         element_counts = dict(element_counts)\n",
    "#         print(sum(getDictValues(element_counts)))\n",
    "\n",
    "#         # Get relative counts if specified\n",
    "#         if relative:\n",
    "#             total = sum(getDictValues(element_counts))\n",
    "#             for key in getDictKeys(element_counts):\n",
    "#                 element_counts[key] = element_counts[key] / total\n",
    "        \n",
    "#         return element_counts\n",
    "\n",
    "\n",
    "# t = Trajectory(r\"trajectories.txt\")\n",
    "# t.countTrajectories(relative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_point_probs = {   \n",
    "#         'J': 0.09741,\n",
    "#         'B': 0.08765,\n",
    "#         'C': 0.17319,\n",
    "#         'D': 0.17546,\n",
    "#         'F': 0.09144,\n",
    "#         'I': 0.08925,\n",
    "#         'G': 0.01681,\n",
    "#         'H': 0.08812,\n",
    "#         'E': 0.17409,\n",
    "#         'A': 0.00658\n",
    "# }\n",
    "# cities = getDictKeys(start_point_probs)\n",
    "# probs = getDictValues(start_point_probs)\n",
    "# np.random.seed(123)\n",
    "# start_points = []\n",
    "# for i in range(100000):\n",
    "#     start = np.random.choice(cities, p=probs)\n",
    "#     start_points.append([start])\n",
    "# # start_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(123)\n",
    "# getNextStep = lambda probs: np.random.choice(next_steps, p=probs)\n",
    "\n",
    "# for sp in start_points:\n",
    "#     next_point = sp[0]\n",
    "#     weights = trajectory_weights.loc[next_point, :].values\n",
    "\n",
    "#     for _ in range(3):\n",
    "\n",
    "#         next_point_2 = getNextStep(weights)\n",
    "\n",
    "#         if getIdxNextStep(next_point_2) < getIdxNextStep(next_point):\n",
    "\n",
    "#             if np.random.choice([0, 1], p=[0.999, 0.001]) == 1:\n",
    "\n",
    "#                 print(next_point_2, next_point)\n",
    "#                 if next_point_2 not in sp:\n",
    "#                     next_point = next_point_2\n",
    "#                     sp.append(next_point)\n",
    "#                 if next_point == \"NA\":\n",
    "#                     break\n",
    "#                 weights = trajectory_weights.loc[next_point, :].values\n",
    "            \n",
    "#             else:\n",
    "#                 continue\n",
    "\n",
    "#         else:\n",
    "#             if next_point_2 not in sp:\n",
    "#                 next_point = next_point_2\n",
    "#                 sp.append(next_point)\n",
    "#             if next_point == \"NA\":\n",
    "#                 break\n",
    "#             weights = trajectory_weights.loc[next_point, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajectories = deepcopy(start_points)\n",
    "# trajectories = [t for t in trajectories if len(t) > 2]\n",
    "# trajectories = [t[:-1] if t[-1] == 'NA' else t for t in trajectories]\n",
    "# trajectories_str = [\" \".join(t) for t in trajectories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the file in write mode\n",
    "# file_path = r\"trajectories.txt\"\n",
    "# with open(file_path, 'w') as file:\n",
    "#     # Iterate over the list of strings\n",
    "#     for string in trajectories_str:\n",
    "#         # Write each string followed by a newline character to the file\n",
    "#         file.write(string + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Generate 10 cities -- call them A, ..., J\n",
    "# cities = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "# hubs = ['B', 'F', 'I']\n",
    "# colors = ['blue' if city in hubs else 'red' for city in cities]\n",
    "# markers = ['*' if city in hubs else 'o' for city in cities]\n",
    "# sizes = [350 if city in hubs else 150 for city in cities]\n",
    "# text_sizes = [15 if city in hubs else 10 for city in cities]\n",
    "# labels = ['hub' if city in hubs else 'town' for city in cities]\n",
    "\n",
    "# np.random.seed(12)\n",
    "# # Generate random x and y coordinates\n",
    "# X = np.random.randint(0, 100, len(cities))\n",
    "# Y = np.random.randint(0, 100, len(cities))\n",
    "\n",
    "# # Sort cities, X, and Y, based on x position\n",
    "# sorted_cities = sorted(cities, key=lambda city: dict(zip(cities, X))[city])\n",
    "# X_ordered = sorted(X)\n",
    "# Y_ordered = sorted(Y, key=lambda y: dict(zip(Y, X))[y])\n",
    "\n",
    "# # distance_matrix = np.zeros((len(sorted_cities), len(sorted_cities)))\n",
    "# # for i in range(len(sorted_cities)):\n",
    "# #     for j in range(len(sorted_cities)):\n",
    "# #         distance_matrix[i, j] = euclDist([X_ordered[i], Y_ordered[i]], \n",
    "# #                                          [X_ordered[j], Y_ordered[j]])\n",
    "        \n",
    "# # plt.figure(figsize=(15, 8))\n",
    "# # plt.imshow(distance_matrix, cmap='viridis')\n",
    "# # plt.colorbar()\n",
    "# # plt.xticks(range(len(sorted_cities)), sorted_cities)\n",
    "# # plt.yticks(range(len(sorted_cities)), sorted_cities)\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords = list(zip([int(x) for x in X_ordered], [int(y) for y in Y_ordered]))\n",
    "# coords_dict = dict(sorted(list(zip(sorted_cities, coords)), key = lambda x: x[0]))\n",
    "# write_to_json(coords_dict, r'city_coordinates.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert(s): \n",
    " \n",
    "#     # initialization of string to \"\" \n",
    "#     new = \"\" \n",
    " \n",
    "#     # traverse in the string \n",
    "#     for x in s: \n",
    "#         new += x \n",
    " \n",
    "#     # return string \n",
    "#     return new \n",
    "\n",
    "# def print_array2d(a, round_=2):\n",
    "#     a_ = np.round(a, round_)\n",
    "#     shape = a_.shape\n",
    "#     for r in range(shape[0]):\n",
    "#         print('|', end = ' ')\n",
    "#         for c in range(shape[1]):\n",
    "#             if c < shape[1] - 1:\n",
    "#                 e = [' ']*8\n",
    "#                 e[:len(str(a_[r, c]))] = str(a_[r, c])\n",
    "#                 e = convert(e)\n",
    "#                 print(e, end=\" | \")\n",
    "#             else:\n",
    "#                 e = [' ']*8\n",
    "#                 e[:len(str(a_[r, c]))] = str(a_[r, c])\n",
    "#                 e = convert(e)\n",
    "#                 print(e, end=\" | \")\n",
    "#                 print()\n",
    "#         # print()\n",
    "# ds = np.zeros_like(distance_matrix)\n",
    "# for row, div in zip(range(len(distance_matrix)), np.linspace(1, 2, len(distance_matrix))):\n",
    "#     ds[row] = distance_matrix[row] / (np.sum(distance_matrix[row])*(div*1.01))\n",
    "# print_array2d(ds)\n",
    "# np.sum(ds, axis=1)\n",
    "# pd.DataFrame(ds, index=sorted_cities, columns=sorted_cities).to_excel(r\"trajectory_weights.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
